---
title: "COMPSCIX 415.2 Homework 4"
author: "Lian Shen"
date: "February 19, 2019"
output: 
  html_document:
    self_contained: true
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.align = 'center')
```

```{css, echo=FALSE}
pre code, pre, code {
  white-space: pre !important;
  overflow-x: scroll !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
```

```{r}
library(tidyverse)
library(nycflights13)
```
***
##**5.6.7 Exercises**
###**2.**  
**Come up with another approach that will give you the same output as `not_cancelled %>% count(dest)` and `not_cancelled %>% count(tailnum, wt = distance)` (without using `count()`).**

```{r}
not_cancelled <- flights %>% filter(!is.na(dep_delay), !is.na(arr_delay))
#number of not_cancelled flights instances by dest
#not_cancelled %>% count(dest)
not_cancelled %>% group_by(dest) %>% summarize(n = n())
#total distance each not_cancelled flight flew by tailnum
#not_cancelled %>% count(tailnum, wt = distance)
not_cancelled %>% group_by(tailnum) %>% summarize(n = sum(distance))
```

***
###**4.**  
**Look at the number of cancelled flights per day. Is there a pattern? Is the proportion of cancelled flights related to the average delay?**

```{r}
cancelled <- flights %>% filter(is.na(dep_delay) & is.na(arr_delay))
#number of cancelled flights per day
cancelled_freq <- cancelled %>% group_by(year, month, day) %>% summarize(n = n()) %>% mutate(date = ISOdate(year, month, day))
cancelled_freq %>% ggplot(aes(x = date, y = n)) + geom_col() + xlab("Date") + ylab("Number of cancelled flights") + ggtitle("Frequency of Cancelled Flights per Day")
#proportion of cancelled flights per day
cancelled_prop <- flights %>% group_by(year, month, day) %>% summarize(cancelled_proportion = mean(is.na(dep_delay) & is.na(arr_delay))) %>% mutate(date = ISOdate(year, month, day))
cancelled_prop %>% ggplot(aes(x = date, y = cancelled_proportion)) + geom_col() + geom_smooth(se = FALSE)  + xlab("Date") + ylab("Proportion of cancelled flights") + ggtitle("Proportion of Cancelled Flights per Day")
#average delay per day
delays <- flights %>% group_by(year, month, day) %>% summarize(average_delay = mean(arr_delay, na.rm = TRUE) + mean(dep_delay, na.rm = TRUE)) %>% mutate(date = ISOdate(year, month, day))
delays %>% ggplot(aes(x = date, y = average_delay)) + geom_jitter() + geom_smooth(se = FALSE) + xlab("Date") + ylab("Average delay (min)") + ggtitle("Average Flight Delay per Day")
```

There is a pattern that is shared between the number of flights cancelled per day and the proportion of flights cancelled per day. The frequency of cancelled flights seems to trend with the season. Months around July and January see spikes in the frequency of cancelled flights. The same trend is noticeable in the flight delay graph. The curve increases right around the months of July and January. It is hard to say whether the proportion of cancelled flights is related to the average delay though. They could both be related to an external factor like school summer and winter breaks being the airports' busy seasons.

***
###**6.**  
**What does the `sort` argument to `count()` do. When might you use it?**
```{r}
not_cancelled %>% count(dest, sort = TRUE)
```

The `sort` argument will order the output of `count()`, which is `n`, in descending order if set to `TRUE`. This could be useful when the user wants to check to see if he/she should filter the data first to remove any low counts of observations that may skew the data or if the user wants to check of the number of observations is sufficiently high enough.

***
###**5.**
**Which carrier has the worst delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about `flights %>% group_by(carrier, dest) %>% summarise(n())`)**
```{r, fig.height=10, fig.width=20}
delay_by_carrier_dest <- flights %>% group_by(carrier, dest) %>% summarise(average_delay = mean(arr_delay, na.rm = TRUE))
delay_by_carrier_dest %>% ggplot() + geom_col(aes(x = carrier, y = average_delay, fill = dest), position = "dodge",show.legend = FALSE) + xlab("Carrier") + ylab("Average delay (min)") + ggtitle("Average Flight Delay by Carrier and Destination Airport")
#add average airport delay to data
delay_by_dest <- flights %>% group_by(dest) %>% summarise(average_dest_delay = mean(arr_delay, na.rm = TRUE))
carrier_delays_dest_delays <- left_join(delay_by_carrier_dest, delay_by_dest)
delay_by_dest %>% ggplot() + geom_col(aes(x = dest, y = average_dest_delay, fill=dest),show.legend = FALSE) + xlab("Airport") + ylab("Average delay (min)") + ggtitle("Average Delay at Destination Airport") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
#remove dest airport's average delay effects from carrier
#difference from airport delay is carrier delay without airport delay effects
carrier_delays_baseline <- carrier_delays_dest_delays %>% mutate(isolated_carrier_delay = average_delay-average_dest_delay)
carrier_delays_baseline %>% ggplot(aes(x = carrier, y = isolated_carrier_delay, fill = dest)) + geom_col(position = "dodge",show.legend = FALSE) + xlab("Carrier") + ylab("Average delay (min)") + ggtitle("Baseline Average Carrier Delay without Airport Delay Effects")
#ignore dest and get average_carrier_delay now that airport delays is accounted for
carrier_delays <- carrier_delays_baseline %>% group_by(carrier) %>% summarize(average_carrier_delay = mean(isolated_carrier_delay, na.rm = TRUE))
carrier_delays %>% ggplot(aes(x = carrier, y = average_carrier_delay)) + geom_col() + xlab("Carrier") + ylab("Average delay (min)") + ggtitle("Average Carrier Delay")
```

After removing the effects of the average airport delays from each carrier at the specific airport and taking the carriers' average delays, OO seems to have the worst delays.

***
##**10.5 Exercises**
###**1.**
**How can you tell if an object is a tibble? (Hint: try printing `mtcars`, which is a regular data frame).**

```{r}
class(mtcars)
```
An object is a tibble if `[1] "tbl_df"     "tbl"        "data.frame"` is returned when `class(object)` is called. An object is a data frame when `[1] "data.frame"` is returned.

***
###**2.**
**Compare and contrast the following operations on a `data.frame` and equivalent tibble. What is different? Why might the default data frame behaviours cause you frustration?**  
**`df <- data.frame(abc = 1, xyz = "a")`**  
**`df$x`**  
**`df[, "xyz"]`**  
**`df[, c("abc", "xyz")]`**  
```{r, echo=FALSE}
df <- data.frame(abc = 1, xyz = "a")
```
```{r}
df_tibble <- as_tibble(df)
df$x
df_tibble$x
df[, "xyz"]
df_tibble[, "xyz"]
df[, c("abc", "xyz")]
df_tibble[, c("abc", "xyz")]
```

Tibbles are more strict than data frames and provide better formatting. The code `df$x` shouldn't return anything since there is no variable name `x` in the data frame `df`, but it still returns the value `a` since its existing variable name `xyz` was a partial match. Extracting by a variable name that doesn't exist in a tibble will return `NULL`, which is expected behavior since the variable doesn't exist.

`[, "xyz"]` returns all rows of variable "xyz". However, the behavior for data frames isn't expected; it returns the rows as an array and specifies each value as a "level". The output format makes it difficult to understand. Calling this code with a tibble returns something more readable: the values separated by rows as a table, not an array.

Specifying more than one variable in `[, c("abc","xyz")]` will force a data frame to return a table instead of an array. In this case, the output for a data frame and a tibble are similar, but the tibble will show the data type of each variable.

***
###**3.**
**If you have the name of a variable stored in an object, e.g. `var <- "mpg"`, how can you extract the reference variable from a tibble?**

```{r}
my_tibble <- tibble(col1 = c(1,3,5), mpg = c(25,30,27))
var <- "mpg"
#doesn't work
my_tibble$var #have to use my_tibble$mpg
#works
my_tibble[[var]]
my_tibble[var]
my_tibble[,var]
```

***
###**6.**
**What option controls how many additional column names are printed at the footer of a tibble?**

Printing a tibble is designed to not overwhelm the console if the dataset is large. By default, it will print the first 10 rows and the columns that fit on the screen. To change how many additional columns to print, this can be set in the `print` command's parameter `width`. Setting `width` to `Inf` will print all columns. To change the default print behavior, set `options` parameter `tibble.width` to change the output width (`Inf` will show all columns). `tibble.max_extra_cols` sets the number of extra columns printed in reduced form.

***
##**12.3.3 Exercises**
###**2.**
**Why does this code fail?**  
**`table4a %>% gather(1999, 2000, key = "year", value = "cases")`**  
**`#> Error in inds_combine(.vars, ind_list): Position must be between 0 and n`**  

The code fails because the gathered columns' names are numeric and not strings. To specify the year columns, the character \` must surround the variable names.
```{r}
table4a %>% gather(`1999`, `2000`, key = "year", value = "cases")
```


***
###**3.**
**Why does spreading this tibble fail? How could you add a new column to fix the problem?**  
**`people <- tribble(`**  
**`  ~name,             ~key,    ~value,`**  
**`  #-----------------|--------|------`**  
**`  "Phillip Woods",   "age",       45,`**  
**`  "Phillip Woods",   "height",   186,`**  
**`  "Phillip Woods",   "age",       50,`**  
**`  "Jessica Cordero", "age",       37,`**  
**`  "Jessica Cordero", "height",   156`**  
**`)`**

Since tibble `people` has more observations for "Phillip Woods" than the unique `key` values of the tibble, spreading would not work since the function wouldn't know which identifier `age` to use as the new column and which `age` value to associate the only `height` value to.

```{r}
people <- tribble(
  ~name,             ~key,    ~value,     ~datestamp,
  #-----------------|--------|----------|---------
  "Phillip Woods",   "age",       45,   "05/06/2011",
  "Phillip Woods",   "height",   186,   "05/06/2011",
  "Phillip Woods",   "age",       50,   "11/25/2016",
  "Jessica Cordero", "age",       37,   "09/13/1999",
  "Jessica Cordero", "height",   156,   "09/13/1999"
)
people %>% spread(key = key, value = value)
```

Adding another column adds another variable to make the row unique after spreading. Without the extra column, the spreading algorithm wouldn't be able to explicitly organize the data table into valid rows.


***
###**4.**
**Tidy the simple tibble below. Do you need to spread or gather it? What are the variables?**  
**`preg <- tribble(`**  
**`  ~pregnant, ~male, ~female,`**  
**`  "yes",     NA,    10,`**  
**`  "no",      20,    12`**  
**`)`**  

```{r, echo=FALSE}
preg <- tribble(
  ~pregnant, ~male, ~female,
  "yes",     NA,    10,
  "no",      20,    12
)
```

```{r}
preg %>% gather(male, female, key = "gender", value = "cases")
```

The initial variables are pregnant, male, and female. After tidying the data with `gather`, the new variables are pregnant, gender, and cases.


***
##**12.4.3 Exercises**
###**1.**
**What do the extra and fill arguments do in `separate()`? Experiment with the various options for the following two toy datasets.**  
**`tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% `**  
**`  separate(x, c("one", "two", "three"))`**  

**`tibble(x = c("a,b,c", "d,e", "f,g,i")) %>% `**  
**`  separate(x, c("one", "two", "three"))`**  

The `separate` function separates one column into multiple columns. The `extra` parameter is used when the `sep` parameter is a character vector. It sets the control of what happens when there are too many values in the character vector. It can be set to `warn` to display a warning when extra values are dropped, `drop` to drop the extra values without a warning, or `merge` to split at most `n` number of times where `n` is the length of the new variables to create.  
The `fill` parameter is used when the `sep` parameter is a character vector. It controls what happens when there are not enough pieces. It can be set to `warn` to display a warning and fill from the right, `right` to fill the missing values on the right, or `left` to fill the missing values on the left.

```{r, warning=TRUE}
tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, c("one", "two", "three"), sep = ',', extra="warn")
tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, c("one", "two", "three"), sep = ',', extra="merge")

tibble(x = c("a,b,c", "d,e", "f,g,i")) %>% 
  separate(x, c("one", "two", "three"), sep = ',', fill="warn")
tibble(x = c("a,b,c", "d,e", "f,g,i")) %>% 
  separate(x, c("one", "two", "three"), sep = ',', fill="left")
```

***
###**2.**
**Both `unite()` and `separate()` have a remove argument. What does it do? Why would you set it to `FALSE`?**  

For `separate`, the `remove` argument sets whether to keep the original column that separated in the output. For `unite`, the argument sets whether to keep the original columns that were united in the output. By default, `remove` is set to `TRUE` so the original data is hidden. Set it to `FALSE` to view the original data and how it was transformed.

***
##**Baby Names**
**Follow these steps:**   
**- Download the baby_names.txt file from Canvas which is in the Homework 4 assignment section.**  
**- Load this file into R correctly and take a glimpse of the output.**  
```{r}
file_path <- "C:\\Users\\lshen\\Documents\\Data Science\\baby_names.txt"
name_data <- read_delim(file = file_path, delim = "|")
glimpse(name_data)
```

**- Export this file as a csv file and call it ‘baby_names.csv’.**  
```{r}
write_csv(name_data, path = "C:\\Users\\lshen\\Documents\\Data Science\\baby_names.csv")
```

**- Reload the baby_names.csv file and take another glimpse.**  
```{r}
file_path <- "C:\\Users\\lshen\\Documents\\Data Science\\baby_names.csv"
name_data_csv <- read_csv(file = file_path)
glimpse(name_data_csv)
```

**- Show all of your code and the output. There should be two data import lines of code, one data export line of code, and two glimpses of the data.**  
